---
title: "Scraping datos de canciones y letras + EDA"
author: "Agustin Gonzalez Lamenza"
date: last-modified
date-format: long
format: 
  html:
    toc: true
    number-sections: true
    code-fold: true
    df-print: paged
    embed-resources: true
    output-file: index.html
execute:
  echo: true
  warning: false
---

# Carga de packages y datos

```{r}
# Carga de paquetes necesarios
library(tidyverse)
library(ggplot2)
library(wordcloud)
library(tidytext)
library(textdata)
library(stopwords)
library(here)
library(pastecs)
library(psych)

# Carga de los datos
songs <- read_tsv(here("data", "songs.tsv"))
lyrics <- read_tsv(here("data", "lyrics.tsv"))

songs_unique <- songs %>%
  distinct(track_name, .keep_all = TRUE)

lyrics_unique <- lyrics %>%
  distinct(song_name, .keep_all = TRUE)

# Realizar el join después de eliminar duplicados
data <- songs_unique %>%
  mutate(track_name = str_to_lower(track_name)) %>%
  inner_join(
    lyrics_unique %>% mutate(song_name = str_to_lower(song_name)),
    by = c("track_name" = "song_name")
  )
```

## Dataframe songs

```{r}
songs_unique %>%
  head() %>%
  mutate(across(everything(), ~ paste0(
    '<span title="', ., '" style="max-width: 150px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;">',
    substr(., 1, 40), "...</span>"
  ))) %>%
  knitr::kable("html", escape = FALSE)
```

## Dataframe lyrics

```{r}
# Crear la tabla con truncamiento y tooltip para todas las columnas
lyrics_unique %>%
  head() %>%
  mutate(across(everything(), ~ paste0(
    '<span title="', ., '" style="max-width: 150px; overflow: hidden; text-overflow: ellipsis; white-space: nowrap;">',
    substr(., 1, 60), "...</span>"
  ))) %>%
  knitr::kable("html", escape = FALSE)
```

# Análisis descriptivo

## Distribución de duración de las canciones

```{r}
# Gráfico de distribución de la duración
ggplot(data, aes(x = track_duration_ms / 1000)) +
  geom_histogram(binwidth = 30, fill = "steelblue", color = "white") +
  labs(
    title = "Distribución de la duración de las canciones",
    x = "Duración (segundos)",
    y = "Frecuencia"
  ) +
  theme_minimal()
```

## Relación entre energía y bailabilidad

```{r}
# Gráfico de dispersión
ggplot(data, aes(x = track_energy, y = track_danceability)) +
  geom_point(alpha = 0.7, color = "darkorange") +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(
    title = "Relación entre energía y bailabilidad",
    x = "Energía",
    y = "Bailabilidad"
  ) +
  theme_minimal()
```

## Estadísticas descriptivas de features numericos

```{r}
# Seleccionar solo columnas numéricas
numerical_features <- songs_unique %>%
  select(where(is.numeric))

# Resumen estadístico de las características numéricas
res <- pastecs::stat.desc(numerical_features) %>%
  as.matrix() %>%
  as.data.frame() %>%
  round(2)

res <- format(res, scientific = FALSE)

knitr::kable(data.frame(res), digits = 2)
```

## Grafico de correlación

```{r}
pairs.panels(numerical_features,
  method = "pearson", # metodo de correlación
  hist.col = "#00AFBB",
  density = TRUE,
  ellipses = F
)
```

# Análisis textual

## Establecer una semilla para reproducibilidad
Util para generar los wordcloud

```{r}
set.seed(123)
```


## Frecuencia de palabras

```{r}
# Obtener las stopwords en español
stopwords_es <- stopwords("es")

# Crear un vector con las stopwords adicionales
# Sumo algo muy repetitivo en Soda (solo valido para Soda)
stopwords_adicionales <- c("ay", "oh")

# Combinar las stopwords en español con las adicionales
stopwords_completas <- c(stopwords_es, stopwords_adicionales)

# Limpieza de texto y tokenización
tokens <- data %>%
  unnest_tokens(word, lyrics) %>%
  anti_join(tibble(word = stopwords_completas), by = "word") %>%
  count(word, sort = TRUE)

# Visualización de las palabras más frecuentes
tokens %>%
  top_n(20) %>%
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "purple") +
  coord_flip() +
  labs(
    title = "Palabras más frecuentes en las letras",
    x = "Palabras",
    y = "Frecuencia"
  ) +
  theme_minimal()
```

## Nube de palabras

```{r}
wordcloud::wordcloud(
  words = tokens$word,
  freq = tokens$n,
  max.words = 100,
  colors = brewer.pal(8, "Dark2")
)
```

## Análisis de sentimientos

```{r}
# Análisis de sentimientos usando el léxico NRC
sentiments <- tokens %>%
  inner_join(get_sentiments("nrc"), by = "word") %>%
  count(sentiment, sort = TRUE)

# Visualización de los sentimientos predominantes
ggplot(sentiments, aes(x = reorder(sentiment, n), y = n)) +
  geom_col(fill = "skyblue") +
  coord_flip() +
  labs(
    title = "Distribución de sentimientos en las letras",
    x = "Sentimiento",
    y = "Frecuencia"
  ) +
  theme_minimal()
```

## Nube de palabras de sentimientos

```{r}
wordcloud::wordcloud(
  words = sentiments$sentiment,
  freq = sentiments$n,
  min.freq = 1,
  colors = brewer.pal(8, "Dark2"),
)
```